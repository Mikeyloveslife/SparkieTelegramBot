import os
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')

from create_bot import dp, bot
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram import Dispatcher
from aiogram.types import ReplyKeyboardRemove, Message, CallbackQuery
from aiogram.dispatcher.filters import Text
from aiogram.dispatcher import FSMContext


from keyboards.keyboards_eng import menu_kb, in_text_davinci_003_kb, model_settings_kb, max_length_kb, temperature_replykeyboard, temperature_inlinekeyboard, language_kb, model_kb, return_kb, in_gpt_turbo_kb


from data_base.get_sqlite import *

class Form(StatesGroup):
  in_gpt_turbo = State()
  in_text_davinci_003 = State()
  in_model_settings = State()
  in_choose_model = State()
  in_max_length = State()
  in_temperature = State()
    

db = Database('user_settings.db')

async def create_completion(chat_history, message):
  completion = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
      {"role": "system", "content": f"You are a helpful assistant called Sparky. Here is the history of your chat with the user '{chat_history}'. Use the chat history only if it's related to the new prompt from a user"},
      {"role": "user", "content": f"{message}\n"}])
  return completion

async def sum_completion(chat_history, new_prompt, new_response):
  completion = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
      {"role": "system", "content": f"You are an assistant called Sparky who summurizes the most important information from the chat. The summurization should not exceed 500 tokens. The contents to summurize include: chat history, new prompt, new response. Here they are consecutively: 1 - '{chat_history}' 2 - ''{new_prompt} 3 - {}  "},
      {"role": "user", "content": f"{message}\n"}])
  return completion
  

                ### Chat with Sparkie ###
#@dp.message_handler(Text(equals='Chat with Sparkie'))
async def chat_with_sparkie_eng(message: Message):
  user_id = message.from_user.id
  model = get_model(db, user_id)
  if model == 'gpt-3.5-turbo':
    await Form.in_gpt_turbo.set()
    reply_markup = in_gpt_turbo_kb
  elif model == 'text-davinci-003':
    await Form.in_text_davinci_003.set()
    reply_markup = in_text_davinci_003_kb
  await bot.send_message(user_id, "Hello you can ask me anything you want. Mind the number of tokens you have in balance.", reply_markup=reply_markup)


                 ### in_gpt_turbo handler ###
#@dp.message_handler(state=Form.in_gpt_turbo)
async def in_gpt_turbo_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  if message.text == '‚¨ÖÔ∏è':
    await state.finish()
    await bot.send_message(user_id, "Welcome to the main menu. Please select an option:", reply_markup=menu_kb)
  elif message.text == "üïπ\nChoose model":
    await Form.in_choose_model.set()
    await bot.send_message(user_id, f"Your current model is {get_model(db, user_id)}.", reply_markup=return_kb)
    await bot.send_message(user_id, "Choose one of the supported models:", reply_markup=model_kb)
  else:
    try:
      completion = await create_completion(message.text)
      await bot.send_message(user_id, completion["choices"][0]["message"]["content"])
      print(get_chat_history(db, user_id))
      update_chat_history(db, user_id, completion["choices"][0]["message"]["content"])
      tokens = get_token_balance(db, user_id)
      num_tokens_used = completion["usage"]["total_tokens"]
      print('\nnum_tokens_used:', num_tokens_used)
      subtract_tokens(db, user_id, num_tokens_used)
      await bot.send_message(user_id, f"Token balance: {tokens-num_tokens_used}")
    except Exception as e:
      await bot.send_message(user_id, "An error occurred during the model interaction. Please try again later.")
      print(e)

    

               ### Chat with Sparkie in_text_davinci_003 ###
#@dp.message_handler(state=Form.in_text_davinci_003)
async def in_text_davinci_003_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  if message.text == '‚¨ÖÔ∏è':
    await state.finish()
    await bot.send_message(user_id, "Welcome to the main menu. Please select an option:", reply_markup=menu_kb)
  elif message.text == "‚öôÔ∏è\nModel settings":
    await Form.in_model_settings.set()
    await bot.send_message(user_id, "Select one of the settings:", reply_markup=model_settings_kb)
  elif message.text == "üïπ\nChoose model":
    await Form.in_choose_model.set()
    await bot.send_message(user_id, f"Your current model is {get_model(db, user_id)}.", reply_markup=return_kb)
    await bot.send_message(user_id, "Choose one of the supported models:", reply_markup=model_kb)
  else:
    try:
### check if a user's token balance is less than the max length ###
      tokens, max_length, temperature = get_text_davinci_003_settings(db, user_id)
      print(tokens, max_length, temperature)
      if tokens < max_length:
        await bot.send_message(user_id, f"Insufficient token balance: {tokens}")
        return
      completion = openai.Completion.create(
      engine="text-davinci-003",
      prompt=(f"{message.text}\n"),
      max_tokens=max_length,
      n = 1,
      stop=None,
      temperature=temperature,
      )
      await bot.send_message(user_id, completion["choices"][0]["text"])
      num_tokens_used = completion["usage"]["total_tokens"]
      print('num_tokens_used:' ,num_tokens_used)
      subtract_tokens(db, user_id, num_tokens_used)
      await bot.send_message(user_id, f"Token balance: {tokens-num_tokens_used}")
    except Exception as e:
      await bot.send_message(user_id, "An error occurred during the model interaction. Please try again later.")
      print(e)

                ### In_prompt_settings handler ###
#@dp.message_handler(state=Form.in_model_settings)
async def in_prompt_settings_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  if message.text == '‚¨ÖÔ∏è':
    await Form.in_text_davinci_003.set()
    await bot.send_message(user_id, "You can keep chatting.", reply_markup=in_text_davinci_003_kb)
  elif message.text == 'Maximum length':
    await Form.in_max_length.set()
    current_max_length = get_max_length(db, user_id)
    await bot.send_message(user_id, f"Your current maximum length is {current_max_length}.\nPlease enter your desired length:", reply_markup=max_length_kb)
  elif message.text == 'Temperature':
    await Form.in_temperature.set()
    current_temperature = get_temperature(db, user_id)
    await bot.send_message(user_id, f"Your current Temperature is {current_temperature}.", reply_markup=temperature_replykeyboard)
    await bot.send_message(user_id, "Please enter the desired value:", reply_markup=temperature_inlinekeyboard)

                  ### Processing Max_length ###
#@dp.message_handler(state=Form.in_max_length)
async def in_max_length_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  try:
    max_length = int(message.text)
    if max_length > 4097:
      await bot.send_message(user_id, "Max length for this model is 4097 tokens shared between prompt and completion.")
    elif  max_length < 1:
      await bot.send_message(user_id, "Maximum length cannot be less than 1.")
    else:
      update_max_length(db, user_id, max_length)
      await Form.in_model_settings.set()
      await bot.send_message(user_id, f"Maximum length has been updated to {max_length}.", reply_markup=model_settings_kb)
  except ValueError:
    if message.text == '‚¨ÖÔ∏è':
      await Form.in_model_settings.set()
      await bot.send_message(user_id, "Select one of the settings", reply_markup=model_settings_kb)
    elif message.text == "ÔøΩ":
      current_max_length = get_max_length(db, user_id)
      await bot.send_message(user_id, f"Maximum length is the maximum number of tokens to generate. One token is roughly 4 characters for normal English text.\nYou can use up to 4097 tokens shared between prompt and completion.\n\nYour current Maximum length is {current_max_length}\nPlease enter your desired Maximum length.", reply_markup=max_length_kb)
    else:
      await bot.send_message(user_id, "Please input a numerical value.")
  



              ### In_temperature inline handler ###
#@dp.callback_query_handler(lambda c: c.data in ["0", "0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1.0"], state = Form.in_temperature)
async def in_temperature_inline_eng(callback_query: CallbackQuery, state: FSMContext):
  user_id = callback_query.from_user.id
  temperature = float(callback_query.data)
  if 0 <= temperature <= 1:
    update_temperature(db, user_id, temperature)
    await Form.in_model_settings.set()
    await bot.send_message(user_id, f"Temperature has been set to {temperature}.", reply_markup=model_settings_kb)

    
              ### In_temperature reply handler ###
#@dp.message_handler(state=Form.in_temperature)
async def in_temperature_reply_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  try:
    temperature = float(message.text)
    if 0 <= temperature <= 1:
      update_temperature(db, user_id, temperature)
      await Form.in_model_settings.set()
      await bot.send_message(user_id, f"Temperature has been set to {temperature}.", reply_markup=model_settings_kb)
    else:
      raise ValueError
  except ValueError:
    if message.text == "‚¨ÖÔ∏è":
      await Form.in_model_settings.set()
      await bot.send_message(user_id, "Select one of the settings:", reply_markup=model_settings_kb)
    elif message.text == "ÔøΩ":
      current_temperature = get_temperature(db, user_id)
      await bot.send_message(user_id, f"Temperature controls the creativity and randomness of the responses generated by a language model. A low temperature will result in more conservative and deterministic responses, while a higher temperature will produce more varied and unpredictable responses. The temperature can be adjusted depending on the desired level of creativity and coherence for a specific task.\n\nYour current Temperature is {current_temperature}. Please choose the desired value:", reply_markup=temperature_inlinekeyboard)
    else:
      await bot.send_message(user_id, "The temperature setting should be a numerical value between 0 and 1.", reply_markup=temperature_inlinekeyboard)
    
    


            ### In choose model inline keyboard ###
#@dp.callback_query_handler(lambda c: c.data in ["gpt-3.5-turbo", "text-davinci-003"], state = Form.in_choose_model)
async def in_choose_model_inline_eng(callback_query: CallbackQuery, state: FSMContext):
  user_id = callback_query.from_user.id
  model = callback_query.data
  reply_markup = None
  if model == "gpt-3.5-turbo":
    change_model(db, user_id, model)
    await Form.in_gpt_turbo.set()
    reply_markup=in_gpt_turbo_kb
  elif model == 'text-davinci-003':
    change_model(db, user_id, model)
    await Form.in_text_davinci_003.set()
    reply_markup=in_text_davinci_003_kb
  await bot.send_message(user_id, f"The model has been changed to {model}. You can keep chatting.", reply_markup=reply_markup)


              ### In choose model reply keyboard ###
#@dp.message_handler(state=Form.in_choose_model)
async def in_choose_model_reply_eng(message: Message, state: FSMContext):
  user_id = message.from_user.id
  current_model = get_model(db, user_id)
  if message.text == '‚¨ÖÔ∏è':
    if current_model == "gpt-3.5-turbo":
      chat_keyboard = in_gpt_turbo_kb
      await Form.in_gpt_turbo.set()
    elif current_model == "text-davinci-003":
      chat_keyboard = in_text_davinci_003_kb
      await Form.in_text_davinci_003.set()
    await bot.send_message(user_id, "Hello you can ask me anything you want. Mind the number of tokens you have in balance.", reply_markup=chat_keyboard)
  elif message.text == 'ÔøΩ':
    await bot.send_message(user_id, "GPT-3.5 models can understand and generate natural language or code.\n\nü§ñ  gpt-3.5-turbo - Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003.\n\nü§ñ  text-davinci-003 - Can do any language task and gives control over Maximum length and Temperature used in prompts.", reply_markup=return_kb)
    
  
  
    
    


        
    


  

#@dp.message_handler(commands=['/Create_content'])
async def command_create_content_eng(message: Message):
  await bot.send_message(message.from_user.id, 'Choose one of the provided publishing styles or click the button "Your content"', reply_markup=choose_content_type_kb)



  

               ### Registering Handlers ###
def register_handlers_client_ENG(dp : Dispatcher):
  dp.register_message_handler(chat_with_sparkie_eng, Text(equals='üí¨ Chat with Sparky'))
  dp.register_message_handler(in_gpt_turbo_eng, state=Form.in_gpt_turbo)
  dp.register_message_handler(in_text_davinci_003_eng, state=Form.in_text_davinci_003)
  dp.register_message_handler(in_prompt_settings_eng, state=Form.in_model_settings)
  dp.register_message_handler(in_max_length_eng, state=Form.in_max_length)
  dp.register_callback_query_handler(in_temperature_inline_eng, lambda c: c.data in ["0", "0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1.0"], state=Form.in_temperature)
  dp.register_message_handler(in_temperature_reply_eng, state=Form.in_temperature)
  dp.register_callback_query_handler(in_choose_model_inline_eng, lambda c: c.data in ["gpt-3.5-turbo", "text-davinci-003"], state=Form.in_choose_model)
  dp.register_message_handler(in_choose_model_reply_eng, state=Form.in_choose_model)


  



