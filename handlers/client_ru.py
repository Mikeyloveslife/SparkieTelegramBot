import os
import openai
openai.api_key = os.getenv('OPENAI_API_KEY')

from create_bot import dp, bot
from aiogram.dispatcher.filters.state import State, StatesGroup
from aiogram import Dispatcher
from aiogram.types import ReplyKeyboardRemove, Message, CallbackQuery
from aiogram.dispatcher.filters import Text
from aiogram.dispatcher import FSMContext


from keyboards.keyboards_ru import menu_kb, in_text_davinci_003_kb, model_settings_kb, max_length_kb, temperature_replykeyboard, temperature_inlinekeyboard, language_kb, model_kb, return_kb, in_gpt_turbo_kb


from data_base.get_sqlite import *

class Form(StatesGroup):
  in_gpt_turbo_ru = State()
  in_text_davinci_003_ru = State()
  in_model_settings_ru = State()
  in_choose_model_ru = State()
  in_max_length_ru = State()
  in_temperature_ru = State()
    
 


                     ### Chat with Sparkie ###
#@dp.message_handler(Text(equals='Chat with Sparkie'))
async def chat_with_sparkie_ru(message: Message):
  if get_model(message.from_user.id) == 'gpt-3.5-turbo':
    await Form.in_gpt_turbo_ru.set()
    await bot.send_message(message.from_user.id, "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –≤–∞—Å –≤ —á–∞—Ç–µ. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ. –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã –∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –Ω–∞ –≤–∞—à–µ–º —Å—á–µ—Ç—É.", reply_markup=in_gpt_turbo_kb)
  if get_model(message.from_user.id) == 'text-davinci-003':
    await Form.in_text_davinci_003_ru.set()
    await bot.send_message(message.from_user.id, "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –≤–∞—Å –≤ —á–∞—Ç–µ. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ. –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã –∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –Ω–∞ –≤–∞—à–µ–º —Å—á–µ—Ç—É.", reply_markup=in_text_davinci_003_kb)


                   ### Chat with Sparkie in_gpt_turbo ###
#@dp.message_handler(state=Form.in_gpt_turbo_ru)
async def in_gpt_turbo_ru(message: Message, state: FSMContext):
  if message.text == '\u2B05':
    await state.finish()
    await bot.send_message(message.from_user.id, "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –æ–ø—Ü–∏–π:", reply_markup=menu_kb)
  elif message.text == "üïπ\n–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å":
    await Form.in_choose_model_ru.set()
    await bot.send_message(message.from_user.id, f"–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å - —ç—Ç–æ {get_model(message.from_user.id)}.", reply_markup=return_kb)
    await bot.send_message(message.from_user.id, "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:", reply_markup=model_kb)
  else:
    completion = openai.ChatCompletion.create(
      model="gpt-3.5-turbo",
      messages=[
      {"role": "user", "content": f"{message.text}\n"}
      ]
    )
    generated_text = completion["choices"][0]["message"]["content"]
    print(generated_text)
    await bot.send_message(message.from_user.id, generated_text)
    user_id = message.from_user.id
    tokens = get_token_balance(user_id)
    num_tokens_used = completion["usage"]["total_tokens"]
    print('\nnum_tokens_used:' ,num_tokens_used)
    subtract_tokens(user_id, num_tokens_used)
    await bot.send_message(message.from_user.id, f"–ë–∞–ª–∞–Ω—Å —Ç–æ–∫–µ–Ω–æ–≤: {tokens-num_tokens_used}")
    

               ### Chat with Sparkie in_text_davinci_003 ###
#@dp.message_handler(state=Form.in_text_davinci_003_ru)
async def in_text_davinci_003_ru(message: Message, state: FSMContext):
  if message.text == '\u2B05':
    await state.finish()
    await bot.send_message(message.from_user.id, "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –æ–ø—Ü–∏–π:", reply_markup=menu_kb)
  elif message.text == "‚öôÔ∏è\n–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏":
    await Form.in_model_settings_ru.set()
    await bot.send_message(message.from_user.id, "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫:", reply_markup=model_settings_kb)
  elif message.text == "üïπ\n–í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å":
    await Form.in_choose_model_ru.set()
    await bot.send_message(message.from_user.id, f"–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å - —ç—Ç–æ {get_model(message.from_user.id)}.", reply_markup=return_kb)
    await bot.send_message(message.from_user.id, f"–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:", reply_markup=model_kb)
  else:
### check if the user's token balance is less than the token limit ###
    user_id = message.from_user.id
    if get_text_davinci_003_settings(user_id) is None:
      await bot.send_message(message.from_user.id, "–û—à–∏–±–∫–∞: –í—ã –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã.")
      return
    tokens, max_length, temperature = get_text_davinci_003_settings(user_id)
    print(get_text_davinci_003_settings(user_id))
    if tokens < max_length:
      await bot.send_message(message.from_user.id, f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —Å—á–µ—Ç—É: {tokens}")
      return
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=(f"{message.text}\n"),
        max_tokens=max_length,
        n = 1,
        stop=None,
        temperature=temperature,
    )
    generated_text = response["choices"][0]["text"]
    print(generated_text)
    await bot.send_message(message.from_user.id, response["choices"][0]["text"])
    num_tokens_used = response["usage"]["total_tokens"]
    print('num_tokens_used:' ,num_tokens_used)
    subtract_tokens(user_id, num_tokens_used)
    await bot.send_message(message.from_user.id, f"–ë–∞–ª–∞–Ω—Å —Ç–æ–∫–µ–Ω–æ–≤: {tokens-num_tokens_used}")

                ### In_prompt_settings handler ###
#@dp.message_handler(state=Form.in_model_settings_ru)
async def in_prompt_settings_ru(message: Message, state: FSMContext):
  user_id = message.from_user.id
  if message.text == '\u2B05':
    await Form.in_text_davinci_003_ru.set()
    await bot.send_message(message.from_user.id, "–í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ–±—â–µ–Ω–∏–µ.", reply_markup=in_text_davinci_003_kb)
  elif message.text == '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞':
    await Form.in_max_length_ru.set()
    current_max_length = get_max_length(user_id)
    await bot.send_message(message.from_user.id, f"–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç: {current_max_length}.\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –¥–ª–∏–Ω—É:", reply_markup=max_length_kb)
  elif message.text == '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞':
    await Form.in_temperature_ru.set()
    current_temperature = get_temperature(user_id)
    await bot.send_message(message.from_user.id, f"–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç: {current_temperature}.", reply_markup=temperature_replykeyboard)
    await bot.send_message(message.from_user.id, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –≤–∞–º –∑–Ω–∞—á–µ–Ω–∏–µ:", reply_markup=temperature_inlinekeyboard)

                  ### Processing Max_length ###
#@dp.message_handler(state=Form.in_max_length_ru)
async def in_max_length_ru(message: Message, state: FSMContext):
  try:
    max_length = int(message.text)
    if max_length > 4097:
      await bot.send_message(message.from_user.id, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –¥–ª—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 4097 —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –º–µ–∂–¥—É –≤—Ö–æ–¥—è—â–∏–º —Ç–µ–∫—Å—Ç–æ–º –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.")
    elif  max_length < 1:
      await bot.send_message(message.from_user.id, "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ 1.")
    else:
      update_max_length(message.from_user.id, max_length)
      await Form.in_model_settings_ru.set()
      await bot.send_message(message.from_user.id, f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –±—ã–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {max_length}.", reply_markup=model_settings_kb)
  except ValueError:
    if message.text == '\u2B05':
      await Form.in_model_settings_ru.set()
      await bot.send_message(message.from_user.id, "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫:", reply_markup=model_settings_kb)
    elif message.text == "\uFF1F":
      user_id = message.from_user.id
      current_max_length = get_max_length(user_id)
      await bot.send_message(message.from_user.id, f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ - —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –∑–∞ –æ–¥–∏–Ω —Ä–∞–∑. –û–¥–∏–Ω —Ç–æ–∫–µ–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ 4 —Å–∏–º–≤–æ–ª–∞–º –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\n–í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ 4097 —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –º–µ–∂–¥—É –≤—Ö–æ–¥—è—â–∏–º —Ç–µ–∫—Å—Ç–æ–º –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º.\n\n–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç: {current_max_length}\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –≤–∞–º –∑–Ω–∞—á–µ–Ω–∏–µ:", reply_markup=max_length_kb)
    else:
      await bot.send_message(message.from_user.id, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.")

                     ### In_temperature handler ###
#@dp.callback_query_handler(lambda c: c.data in ["0", "0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1.0"], state = Form.in_temperature_ru)
async def in_temperature_inline_ru(callback_query: CallbackQuery, state: FSMContext):
  temperature = float(callback_query.data)
  if 0 <= temperature <= 1:
    update_temperature(callback_query.from_user.id, temperature)
    await Form.in_model_settings_ru.set()
    await bot.send_message(callback_query.from_user.id, f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±—ã–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ: {temperature}.", reply_markup=model_settings_kb)

    
                ### Return button for In_temperature ###
#@dp.message_handler(state=Form.in_temperature_ru)
async def in_temperature_reply_ru(message: Message, state: FSMContext):
  try:
    temperature = float(message.text)
    if 0 <= temperature <= 1:
      update_temperature(message.from_user.id, temperature)
      await Form.in_model_settings_ru.set()
      await bot.send_message(message.from_user.id, f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –±—ã–ª–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ {temperature}.", reply_markup=model_settings_kb)
    else:
      raise ValueError
  except ValueError:
    if message.text == "\u2B05":
      await Form.in_model_settings_ru.set()
      await bot.send_message(message.from_user.id, "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω—É –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫:", reply_markup=model_settings_kb)
    elif message.text == "\uFF1F":
      user_id = message.from_user.id
      current_temperature = get_temperature(user_id)
      await bot.send_message(message.from_user.id, f"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –∏ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤, —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –º–æ–¥–µ–ª—å—é. –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–º –∏ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Ç–≤–µ—Ç–∞–º, —Ç–æ–≥–¥–∞ –∫–∞–∫ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–æ–∑–¥–∞—Å—Ç –±–æ–ª–µ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ –∏ –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–µ –æ—Ç–≤–µ—Ç—ã. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∂–µ–ª–∞–µ–º–æ–≥–æ —É—Ä–æ–≤–Ω—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–≤—è–∑–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏.\n\n–í–∞—à–∞ —Ç–µ–∫—É—â–∞—è –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç: {current_temperature}. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –Ω—É–∂–Ω–æ–µ –≤–∞–º –∑–Ω–∞—á–µ–Ω–∏–µ:", reply_markup=temperature_inlinekeyboard)
    else:
      await bot.send_message(message.from_user.id, "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –æ—Ç 0 –¥–æ 1.", reply_markup=temperature_inlinekeyboard)
    


                           ### In choose model ###
#@dp.callback_query_handler(lambda c: c.data in ["gpt-3.5-turbo", "text-davinci-003"], state = Form.in_choose_model_ru)
async def in_choose_model_inline_ru(callback_query: CallbackQuery, state: FSMContext):
  model = callback_query.data
  if model == "gpt-3.5-turbo":
    change_model(callback_query.from_user.id, model)
    await Form.in_gpt_turbo_ru.set()
    await bot.send_message(callback_query.from_user.id, f"–ú–æ–¥–µ–ª—å –±—ã–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {model}. –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ–±—â–µ–Ω–∏–µ.", reply_markup=in_gpt_turbo_kb)
  elif model == 'text-davinci-003':
    change_model(callback_query.from_user.id, model)
    await Form.in_text_davinci_003_ru.set()
    await bot.send_message(callback_query.from_user.id, f"–ú–æ–¥–µ–ª—å –±—ã–ª–∞ –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ {model}. –í—ã –º–æ–∂–µ—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ–±—â–µ–Ω–∏–µ.", reply_markup=in_text_davinci_003_kb)


    
#@dp.message_handler(state=Form.in_choose_model_ru)
async def in_choose_model_reply_ru(message: Message, state: FSMContext):
  current_model = get_model(message.from_user.id)
  if message.text == '\u2B05':
    if current_model == "gpt-3.5-turbo":
      chat_keyboard = in_gpt_turbo_kb
      await Form.in_gpt_turbo_ru.set()
    elif current_model == "text-davinci-003":
      chat_keyboard = in_text_davinci_003_kb
      await Form.in_text_davinci_003_ru.set()
    await bot.send_message(message.from_user.id, "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é –≤–∞—Å –≤ —á–∞—Ç–µ. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ. –ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã –∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Ç–æ–∫–µ–Ω–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –Ω–∞ –≤–∞—à–µ–º —Å—á–µ—Ç—É.", reply_markup=chat_keyboard)
  elif message.text == '\uFF1F':
    await bot.send_message(message.from_user.id, "–ú–æ–¥–µ–ª–∏ GPT-3.5 –º–æ–≥—É—Ç –ø–æ–Ω–∏–º–∞—Ç—å –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Ç—É—Ä–∞–ª—å–Ω—É—é —Ä–µ—á—å –∏–ª–∏ –∫–æ–¥.\n\nü§ñ  gpt-3.5-turbo - –°–∞–º–∞—è –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å GPT-3.5, –∫–æ—Ç–æ—Ä–∞—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —á–∞—Ç–æ–≤ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∑–∞ 1/10 –æ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ text-davinci-003.\n\nü§ñ  text-davinci-003 - –ú–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å –ª—é–±—É—é –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É –∏ –¥–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –∏ –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É.", reply_markup=return_kb)
    
  
  
    
    


        
    


  

#@dp.message_handler(commands=['/Create_content'])
async def command_create_content_ru(message: Message):
  await bot.send_message(message.from_user.id, 'Choose one of the provided publishing styles or click the button "Your content"', reply_markup=choose_content_type_kb)

#@dp.message_handler(commands=['/Generate_a_picture'])
async def generate_a_picture_ru(message: Message):
  await bot.send_message(message.from_user.id, '–û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –∏–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –Ω–∞—à–∏–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ–º —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∏–Ω–≥–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.')


  

                     ### Registering Handlers ###
def register_handlers_client_RU(dp : Dispatcher):
  dp.register_message_handler(chat_with_sparkie_ru, Text(equals='üí¨ –ß–∞—Ç —Å–æ Sparkie'))
  dp.register_message_handler(in_gpt_turbo_ru, state=Form.in_gpt_turbo_ru)
  dp.register_message_handler(in_text_davinci_003_ru, state=Form.in_text_davinci_003_ru)
  dp.register_message_handler(in_prompt_settings_ru, state=Form.in_model_settings_ru)
  dp.register_message_handler(in_max_length_ru, state=Form.in_max_length_ru)
  dp.register_callback_query_handler(in_temperature_inline_ru, lambda c: c.data in ["0", "0.1", "0.2", "0.3", "0.4", "0.5", "0.6", "0.7", "0.8", "0.9", "1.0"], state=Form.in_temperature_ru)
  dp.register_message_handler(in_temperature_reply_ru, state=Form.in_temperature_ru)
  dp.register_callback_query_handler(in_choose_model_inline_ru, lambda c: c.data in ["gpt-3.5-turbo", "text-davinci-003"], state=Form.in_choose_model_ru)
  dp.register_message_handler(in_choose_model_reply_ru, state=Form.in_choose_model_ru)
  dp.register_message_handler(generate_a_picture_ru, Text(equals='üñºÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'))
  #dp.register_message_handler(command_create_content_ru, Text(equals='Create content'))
  


      ### callback query handler to handle the callback data sent by the inline buttons when "Create content" is pressed ###
  
@dp.callback_query_handler(lambda c: c.data in ["post", "article", "story", "business letter", "commercial", "your content"])
async def process_create_content_ru(callback_query: CallbackQuery):
    data = callback_query.data
    if data == "post":
        # Do something for button 1
        await callback_query.answer("Button Post pressed")
    elif data == "article":
        # Do something for button 2
        await callback_query.answer("Button Article pressed")
    elif data == "story":
        # Do something for button 2
        await callback_query.answer("Button Story pressed")
    elif data == "business letter":
        # Do something for button 2
        await callback_query.answer("Button Business letter pressed")
    elif data == "commercial":
        # Do something for button 2
        await callback_query.answer("Button Commercial pressed")
    elif data == "your content":
        # Do something for button 2
        await callback_query.answer("Button Your content pressed")


